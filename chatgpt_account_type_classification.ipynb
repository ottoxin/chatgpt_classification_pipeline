{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723a4262-5d08-43ee-a6ca-dda76a3d8fa9",
   "metadata": {},
   "source": [
    "# Pipeline for labeling\n",
    "\n",
    "Very first step: Processing dataframe: Decide what columns to keep.\n",
    "\n",
    "- Provide the DataFrame (do not include it in the function). Name the testing using the date format (MM/DD). Provide the directory for storing the data.\n",
    "- Provide background knowledge for the system and prompt for the user.\n",
    "- Record all responses and add each response to the \"chatgpt_output\" column for each data entry in the original DataFrame after the \"TYPE\" column.\n",
    "- Save this DataFrame locally, naming it \"MM/DD\" + testing number (1 if only one testing is done) + \"raw\".\n",
    "- Extract the number for each category and transpose each category to columns. Create the \"chatgpt_label\" column with the highest value among the categories. Then, create a \"consistency\" column (T/F) by comparing the values in the \"TYPE\" and \"chatgpt_label\" columns.\n",
    "- Check for any missing values in the \"chatgpt_label\" column or any other transposed columns. Print the result.\n",
    "- Save this processed DataFrame locally, naming it \"MM/DD\" + testing number (1 if only one testing is done) + \"clean\".\n",
    "- Calculate the performance for each category and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6ed474-e1f1-49db-b164-c9b8ff4fc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"YOUROPENAIKEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3e557-220f-45ca-99bd-0c75bd85aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(df, directory, background_knowledge, prompt_template, index):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame by labeling social media profile data using the OpenAI API. It then stores the results\n",
    "    in specified directory files, computes and prints performance metrics, and handles any missing data in the output.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the social media profile data that needs to be categorized.\n",
    "                           Each row should represent one profile or post with relevant metadata.\n",
    "        directory (str): The path to the directory where the output files will be saved. It should be writable.\n",
    "        background_knowledge (str): A string containing essential background information that the AI model should\n",
    "                                    use to understand the context of the data it will classify.\n",
    "        prompt_template (str): A template string for prompts that will be sent to the OpenAI API. It must include\n",
    "                               placeholders that will be filled with data from the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None: This function directly modifies the input DataFrame and writes to files, but does not return any value.\n",
    "\n",
    "    Raises:\n",
    "        IOError: If there are issues with writing files to the specified directory.\n",
    "        ValueError: If there are missing or improperly formatted data in the DataFrame that prevent the function from executing.\n",
    "    \"\"\"\n",
    "\n",
    "    if 'chatgpt_output' in df.columns:\n",
    "        df.drop(columns=['chatgpt_output'], inplace=True)\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        formatted_entry = \"\\n\".join(f\"{column}: {value}\" for column, value in row.items() if column != 'TYPE')\n",
    "        prompt = prompt_template.format(entry=formatted_entry)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": background_knowledge},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=100,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        chatgpt_output = response.choices[0].message.content\n",
    "        responses.append(chatgpt_output)\n",
    "        df.loc[idx, 'chatgpt_output'] = chatgpt_output\n",
    "\n",
    "    today = datetime.now().strftime(\"%m%d\")\n",
    "    responses_filename = os.path.join(directory, f\"{today}_{index}_responses.txt\")\n",
    "    with open(responses_filename, \"w\") as f:\n",
    "        f.write(\"\\n\".join(responses))\n",
    "\n",
    "    raw_filename = f\"{directory}/{today}_{index}_raw.csv\" ###\n",
    "    df.to_csv(raw_filename, index=False)\n",
    "\n",
    "    # Process responses\n",
    "    categories = ['academia', 'layperson', 'activist', 'politician', 'think tank', 'social media influencer', 'news organizations and news workers'] # CHANGE HERE IF WE HAVE NEW CATEGORIES\n",
    "    df = pd.concat([df, df['chatgpt_output'].apply(lambda x: extract_confidence(x, categories))], axis=1)\n",
    "\n",
    "    df['chatgpt_label'] = df[categories].idxmax(axis=1)\n",
    "    df['consistency'] = df['TYPE'] == df['chatgpt_label']\n",
    "    clean_filename = f\"{directory}/{today}_{index}_clean.csv\" ###\n",
    "    df.to_csv(clean_filename, index=False)\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_data = df[categories + ['chatgpt_label']].isnull().any()\n",
    "    print(\"Missing values in each category:\", missing_data)\n",
    "\n",
    "    # Calculate performance\n",
    "    precision = precision_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "    recall = recall_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "    f1 = f1_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Category': categories,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    print(results_df)\n",
    "\n",
    "def extract_confidence(text, categories):\n",
    "    extracted_values = {}\n",
    "    for category in categories:\n",
    "        pattern = rf\"{category}: (\\d+)%?\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        extracted_values[category] = int(match.group(1)) if match else None\n",
    "    return pd.Series(extracted_values)\n",
    "\n",
    "def re_evaluate_performance(file_path):\n",
    "    \"\"\"\n",
    "    Reloads a processed DataFrame and computes precision, recall, and F1 score for the classification categories.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file containing the processed DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the performance metrics.\n",
    "    \"\"\"\n",
    "    # Load the DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure 'TYPE' and 'chatgpt_label' columns are present for calculation\n",
    "    if 'TYPE' not in df.columns or 'chatgpt_label' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'TYPE' and 'chatgpt_label' columns.\")\n",
    "\n",
    "    # Define the categories\n",
    "    categories = ['academia', 'layperson', 'activist', 'politician', 'think tank', 'social media influencer', 'news organizations and news workers'] # CHANGE HERE IF ANY\n",
    "\n",
    "    # Check if all category columns exist\n",
    "    missing_columns = [col for col in categories if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns for categories: {missing_columns}\")\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    precision = precision_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "    recall = recall_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "    f1 = f1_score(df['TYPE'], df['chatgpt_label'], labels=categories, average=None)\n",
    "\n",
    "    # Prepare the results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Category': categories,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "    # Optionally, print or return the DataFrame\n",
    "    print(results_df)\n",
    "    return df\n",
    "\n",
    "def print_data(df, background_knowledge, prompt_template):\n",
    "\n",
    "    if 'chatgpt_output' in df.columns:\n",
    "        df.drop(columns=['chatgpt_output'], inplace=True)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        formatted_entry = \"\\n\".join(f\"{column}: {value}\" for column, value in row.items() if column != 'TYPE')\n",
    "        prompt = prompt_template.format(entry=formatted_entry)\n",
    "        print(background_knowledge + prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776602c2-baa8-4499-b65b-81757cdff3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of labelling samples.\n",
    "\n",
    "# number of testing\n",
    "index = 1\n",
    "\n",
    "# Directory where the labeled data will be stored\n",
    "output_directory = \"data\"\n",
    "\n",
    "# Background knowledge\n",
    "background_knowledge = \"\"\"\n",
    "You are a social media expert. \n",
    "\"\"\"\n",
    "\n",
    "# Template for the prompts \n",
    "prompt_template = \"\"\"\n",
    "\"\"\n",
    "Here is a dictionary of a series of variables with their meaning, learn then first and use them in the following categorization of a tweet account:\n",
    "\n",
    "Here is a data entry of a twitter post. Recall the previous dictionary then classify the tweet account into [“academia”, “activist”, “layperson”, “politician\", “think tank”, “social media influencer”, “news organizations and news workers”]. Note one account may fulfill multiple categories and only return your confidence level (from 0-100) for each category. You have to decide which category  is more dominant if there is a tie.\n",
    "\n",
    "Note one account may fulfill multiple categories and only return your confidence level (from 0-100) for each category. Your response must be strictly formatted as \"category: %\", such as \"academia: 50%\".\n",
    "\n",
    "Entry:\n",
    "{entry}\n",
    "\"\"\" \n",
    "\n",
    "label_data(df_clean_tk, output_directory, background_knowledge, prompt_template, index)\n",
    "\n",
    "print_data(df_clean_smi, background_knowledge, prompt_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
